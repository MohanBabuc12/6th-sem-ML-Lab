{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGDudN4FrjJi4HanI4OyDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohanBabuc12/6th-sem-ML-Lab/blob/main/ML_Lab%20test%20code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-lxbqGmIWve"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42) # for reproducibility\n",
        "n_samples = 100\n",
        "X1 = np.random.rand(n_samples, 1) * 10\n",
        "X2 = np.random.rand(n_samples, 1) * 5\n",
        "y = 2 * X1 + 3 * X2 + np.random.randn(n_samples, 1)\n",
        "\n",
        "data = {'BMI': X1.flatten(), 'Age': X2.flatten(), 'Sugar': y.flatten()}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['BMI', 'Age']]\n",
        "y = df['Sugar']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Linear Regression Model (Multilinear) ---\n",
        "# Instantiate and train the Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lr_y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Linear Regression model\n",
        "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
        "lr_r2 = r2_score(y_test, lr_y_pred)\n",
        "\n",
        "# Print evaluation metrics for Linear Regression\n",
        "print(\"--- Linear Regression (Multilinear) ---\")\n",
        "print(\"Mean Squared Error:\", lr_mse)\n",
        "print(\"R-squared:\", lr_r2)\n",
        "\n",
        "# --- Random Forest Regression Model ---\n",
        "# Instantiate and train the Random Forest Regression model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest Regression model\n",
        "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
        "rf_r2 = r2_score(y_test, rf_y_pred)\n",
        "\n",
        "# Print evaluation metrics for Random Forest Regression\n",
        "print(\"\\n--- Random Forest Regression ---\")\n",
        "print(\"Mean Squared Error:\", rf_mse)\n",
        "print(\"R-squared:\", rf_r2)\n",
        "\n",
        "# --- Pseudo-accuracy calculation ---\n",
        "def calculate_pseudo_accuracy(actual, predictions, tolerance):\n",
        "    correct_predictions = np.sum(np.abs(actual - predictions) <= tolerance)\n",
        "    return correct_predictions / len(actual)\n",
        "\n",
        "# Define the tolerance\n",
        "tolerance = 2.0  # You can adjust this value\n",
        "\n",
        "print(f\"\\nTolerance for pseudo-accuracy: +/- {tolerance}\")\n",
        "\n",
        "# Calculate pseudo-accuracy for Linear Regression\n",
        "lr_pseudo_accuracy = calculate_pseudo_accuracy(y_test, lr_y_pred, tolerance)\n",
        "print(f\"Linear Regression Pseudo-Accuracy: {lr_pseudo_accuracy:.2f}\")\n",
        "\n",
        "# Calculate pseudo-accuracy for Random Forest Regression\n",
        "rf_pseudo_accuracy = calculate_pseudo_accuracy(y_test, rf_y_pred, tolerance)\n",
        "print(f\"Random Forest Regression Pseudo-Accuracy: {rf_pseudo_accuracy:.2f}\")\n",
        "\n",
        "# --- Plotting ---\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
        "plt.scatter(y_test, lr_y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2) # Ideal line\n",
        "plt.xlabel(\"Actual Target\")\n",
        "plt.ylabel(\"Predicted Target (Linear Regression)\")\n",
        "plt.title(\"Actual vs. Predicted (Linear Regression)\")\n",
        "\n",
        "plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
        "plt.scatter(y_test, rf_y_pred, alpha=0.5, color='green')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2) # Ideal line\n",
        "plt.xlabel(\"Actual Target\")\n",
        "plt.ylabel(\"Predicted Target (Random Forest)\")\n",
        "plt.title(\"Actual vs. Predicted (Random Forest Regression)\")\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlapping titles/labels\n",
        "plt.show()"
      ]
    }
  ]
}